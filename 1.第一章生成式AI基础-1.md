### 第1章 生成式AI基础
本章将介绍生成式AI技术的基础工具与框架，包括Python、TensorFlow、PyTorch及Hugging Face，并比较传统判别式模型与生成式模型。同时，本章将着重介绍在理解广泛数据后生成式AI如何创造新的文本、图像、音频和视频等内容，展示其在各领域应用的潜力和广泛性。此外，本章还将探讨先进模型在不同数据类型和任务中的具体应用，让读者体验生成式AI技术的强大功能。

### 1.1 技术框架介绍
在探索人工智能的澎湃浪潮中，生成式AI作为一颗璀璨的明星，不断展现出强大的能力和潜力。无论是在文本、图像还是音频等多媒体内容的生成上，生成式AI都开启了新的可能性。要想深入理解并应用生成式AI技术，首先需要掌握一些基础工具和框架。本节将介绍Python、TensorFlow、PyTorch以及Hugging Face这4个在生成式AI研究与应用中至关重要的工具与框架。

#### 1.1.1 Python

Python是一门应用广泛的高级编程语言，以简洁明了的语法和强大的库支持而闻名。接下来我们将介绍Python的一些基础概念。

Python的主要优点有如下3个。
- 易于学习。Python的语法接近自然语言语法，这使它成为初学者学习编程的理想选择。
- 广泛应用。Python可以应用于从网站开发到数据科学再到人工智能等众多领域。 
- 庞大社区。Python拥有一个活跃且支持性强的全球社区，无论你遇到任何问题，都可以从中得到解决方案和帮助。

**1. 安装Python**

推荐从Python官方网站下载最新版本的Python。Python官方网站提供了适用于Windows操作系统、macOS和Linux操作系统的安装程序。下载相应版本后，根据安装向导进行安装即可。

**小提示**：

在安装过程中请选中“Add Python X.X to PATH”（将Python X.X添加到PATH）复选框，这样你可以在任何命令行窗口中运行Python。

查看Python版本的命令如下。
```Shell
Python --version
# Python 3.9.13
```
**小提示**：为了减少运行时的错误，推荐使用与本书代码环境一致的Python 3.9.13版本进行开发。

**2. 第1个Python程序**

打开终端，输入python或python3(取决于你使用的操作系统和安装方式)，然后按Enter键，即可进入Python交互模式。在这里，你可以直接输入Python代码并立即看到结果。

尝试输入以下代码并按Enter键。
```Shell
Python
Python 3.9.13 (main, Aug 25 2022, 18:24:45)
[Clang 12.0.0 ] :: Anaconda, Inc. on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> print("Hello, world!")
Hello, world!
```

恭喜你，你刚刚运行了自己的第1个Python程序！

**3. pip的使用**

pip（package installer for Python）可以实现Python包的查询、下载、安装等功能。通常，在安装Python后会自动安装pip。我们可以通过输出pip的版本来确认pip是否已安装。相关命令如下。
```Shell
pip --version
pip 24.0 from **/python3.9/site - packages/pip (python 3.9)
```

pip的使用方式非常方便。可以用pip直接安装一些包，例如通过如下命令安装NumPy(一个用于科学计算的包)。
```Shell
pip install numpy
# 安装最新的NumPy包，如果包已经存在则进行升级
pip install numpy -U
```
本书涉及的项目会包含很多依赖包，可以把这些包放到requirements文件中进行统一管理。相关命令如下。
```Shell
# 将依赖信息打包，并输出到文件中
pip freeze > requirements.txt
# 安装所有文件中指定的包
pip install -r requirements.txt
```
为尽量减少与源代码的差异，本书将为关键注释提供中文译文，其他保持原始内容。


我们可能会遇到找不到某个包的版本，或者由于网络原因导致下载速度比较慢等情况，此时可以尝试手动指定包的源来解决。相关命令如下。
```Shell
pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple
```
网易、腾讯云、阿里云、中国科学技术大学等机构都提供pip的镜像源，你可以在互联网上查找。

#### 1.1.2 TensorFlow

TensorFlow是一个由Google Brain团队开发的开源机器学习库，用于数据流图的数值计算。自从2015年首次发布以来，TensorFlow已经成为深度学习领域中最受欢迎和支持最广泛的框架之一。TensorFlow的设计初衷是促进研究和开发工作的快速迭代，并能够从原型转移到可扩展的生产系统。接下来，我们将通过一个简单的例子介绍TensorFlow的基本使用方法。

首先安装TensorFlow。在1.1.1节中已经安装了pip，这里通过pip直接安装TensorFlow。相关命令如下。
```Shell
Shell
pipinstall tensorflow
```
或者，如果想要安装GPU支持版本的TensorFlow，可以使用如下命令。
```Shell
Shell
pip install tensorflow -gpu
```
**小提示**：为了减少运行时的错误，推荐使用与本书代码环境一致的TensorFlow 2.13.1版本进行开发。

安装推荐版本的TensorFlow、检查TensorFlow是否安装正确及查看GPU是否可用的示例代码如下。
```Shell
# 安装推荐版本的TensorFlow
pip install tensorflow==2.13.1

# 安装完成后，检查TensorFlow是否安装正确
python
>>> import tensorflow as tf
>>> tf.__version__
'2.13.1'
# 查看GPU是否可用（演示环境为macOS，没有GPU）
>>> tf.test.is_gpu_available()
False
```
开发TensorFlow程序时通常涉及两个主要阶段——构建阶段和执行阶段。
- 构建阶段。在这个阶段，需要定义计算图（graph）。计算图是一系列排列成图的TensorFlow指令。节点（node）在图中表示操作（Ops），边（edge）表示在操作之间流动的数据。
- 执行阶段。在这个阶段，使用会话（Session）执行之前构建的计算图。会话负责分配资源和存储操作的状态。 

TensorFlow 2.x版本引入了Eager Execution并将其作为默认模式，这大大简化了使用流程。用户甚至可以不需要理解上述概念，也能按照正常的代码编写流程进行编码。示例代码如下。
```Python
import tensorflow as tf

# 创建一个Tensor
hello = tf.constant('Hello, TensorFlow!')

# Eager Execution允许直接评估Tensor，而不需要Session
print(hello.numpy())
```
下面将创建一个简单的线性模型 $y = Wx + b$，其中，$W$ 和 $b$ 是将要学习的参数。示例代码如下。
```Python
import numpy as np
import tensorflow as tf

# 创建一些样本数据
X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
Y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)

# 定义模型
model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=1, input_shape=[1])
])

# 编译模型
model.compile(optimizer='sgd', loss='mean_squared_error')

# 训练模型
model.fit(X, Y, epochs=500, verbose=0)

# 测试模型
result = model.predict([10.0])
print(result)
# [[18.977683]]
```
通过上述例子，你应该能够对TensorFlow的基本使用方法有所了解。TensorFlow提供了丰富的API，可以用于构建和训练复杂的深度学习模型。随着对TensorFlow的进一步学习，你将能够掌握更多高级功能，以解决实际问题。 

#### 1.1.3 PyTorch

PyTorch是由Facebook AI Research Lab开发的一个开源机器学习库。它提供了类似于NumPy的张量计算功能，且具有强大的GPU加速支持。PyTorch以其简洁的API和用户友好的设计受到广大研究人员和开发者的喜爱，特别适合于快速原型设计和研究。

**1. 安装PyTorch**


在开始使用之前，需要先安装PyTorch。PyTorch官方网站提供了相关的安装命令，你可以根据自己的操作系统和开发环境（包括是否需要GPU支持）选择正确的命令。例如，在大多数情况下，如果你使用的是pip且希望在CPU上运行PyTorch，那么可以使用以下命令安装PyTorch。
```Shell
pip install torch
```

**小提示**：为了减少运行时的错误，推荐使用与本书代码环境一致的PyTorch 2.1.1版本进行开发。

**2. 动手实践**

张量是PyTorch中的基本构建块，可以将其看作高维数组或矩阵。张量支持自动梯度计算，非常适合在神经网络中使用。

创建和操作张量的示例代码如下。
```Python
import torch

# 创建一个未初始化的3×2张量
x = torch.empty(3, 2)
print(x)
# tensor([[0., 0.],
#         [0., 0.],
#         [0., 0.]])

# 创建一个随机初始化的张量
x = torch.rand(3, 2)
print(x)
# tensor([[0.5277, 0.0190],
#         [0.5107, 0.9485],
#         [0.5214, 0.6354]])

# 创建一个用0填充的张量，数据类型为long
x = torch.zeros(3, 2, dtype=torch.long)
print(x)
# tensor([[0, 0],
#         [0, 0],
#         [0, 0]])

# 直接根据数据创建张量
x = torch.tensor([[1, 2], [3, 4], [5, 6]])
print(x)
# tensor([[1, 2],
#         [3, 4],
#         [5, 6]])

# 张量加法
y = torch.rand(3, 2)
print(x + y)
# tensor([[1.4600, 2.7211],
#         [3.6706, 4.3424],
#         [5.8336, 6.1341]])

# 使用torch.add进行加法运算
result = torch.empty(3, 2)
torch.add(x, y, out=result)
print(result)
# tensor([[1.4600, 2.7211],
#         [3.6706, 4.3424],
#         [5.8336, 6.1341]])
```

在训练神经网络时，反向传播算法用于自动计算模型参数的梯度。在PyTorch中，autograd包提供了这项功能。当使用张量进行相关操作时，可以通过设置`requires_grad`为`True`以跟踪对张量的所有操作。

以下是autograd包的一个简单示例。
```Python
import torch

# 创建张量并设置requires_grad为True以跟踪对张量的所有操作
x = torch.ones(2, 2, requires_grad=True)
print(x)
# tensor([[1., 1.],
#         [1., 1.]], requires_grad=True)

# 对张量进行操作
y = x + 2
print(y)
# tensor([[3., 3.],
#         [3., 3.]], grad_fn=<AddBackward0>)

# 因为y是操作的结果，所以它有grad_fn属性
print(y.grad_fn)
# <AddBackward0 object at 0x104bc6e50>

# 对y进行更多操作
z = y * y * 3
out = z.mean()
print(z, out)
# tensor([[27., 27.],
#         [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)

# 计算梯度
out.backward()
# 打印梯度d(out)/dx
print(x.grad)
# tensor([[4.5000, 4.5000],
#         [4.5000, 4.5000]])
```

**3. 构建神经网络**

在PyTorch中，`torch.nn`包负责构建神经网络。`nn.Module`是所有神经网络模块的基类，你的模型也应该继承这个类。

以下是一个简单的前馈神经网络的实现，其中包含一个隐藏层。
```Python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # 包含1个输入图像通道、6个输出通道的3×3的卷积核
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        # 仿射变换: y=Wx+b
        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6来自图像维度
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # 最大池化窗口（2，2）
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = torch.flatten(x, 1)  # 除了批量维度以外展平所有维度
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = Net()
print(net)
```
PyTorch提供了丰富的API和灵活的设计理念，非常适合进行科学研究和原型设计。目前它是整个AI技术框架中非常流行的一个框架。

#### 1.1.4 Hugging Face

Hugging Face是在自然语言处理（Natural Language Processing, NLP）领域一个广受欢迎的开源组织。它提供了大量的预训练模型和工具，可以辅助研究人员和开发者在文本处理、生成、理解等任务上取得突破。`transformers`库是Hugging Face推出的一个核心产品，其中包含多种基于Transformer架构的模型实现，如BERT、GPT、XLNet、T5等，且支持超过100种语言的文本处理任务。



**1. 安装transformers库**

在开始使用之前，首先安装`transformers`库。可以通过如下pip命令轻松完成安装。

```Shell
pip install transformers==4.30.2
```

**小提示**：为了减少运行时的错误，推荐使用与本书代码环境一致的transformers 4.30.2版本进行开发。



**2. 使用transformers库进行文本分类**

这里以一个简单的文本分类任务为例介绍如何使用`transformers`库。假定我们的目标是判断一段文本的情感倾向（如正面或负面）。

- **加载预训练模型及其分词器**

首先，导入必要的库并加载模型及其分词器。示例代码如下。
```Python
from transformers import pipeline

# 加载pipeline，指定任务为sentiment-analysis
classifier = pipeline('sentiment-analysis')
```

这里使用的`pipeline`（管道）是`transformers`库提供的一个高级接口，允许用户快速部署模型到具体的NLP任务上，如文本分类、文本生成、问答等。

- **对文本进行分类**

接下来，可以直接对输入的文本进行情感分析。示例代码如下。

```Python
result = classifier("I love using transformers. It's so easy and powerful!")
print(result)
# [{'label': 'POSITIVE','score': 0.9998}]
``` 

这表示模型将输入的文本判断为正面情感，置信度接近100%。

Hugging Face的transformers库为NLP领域提供了强大而灵活的工具，它不仅包含丰富的预训练模型，还提供易用的API，这使开发者可以快速将最新的NLP技术应用到实际项目中。无论是进行基础的文本分类、问答，还是复杂的文本生成任务，transformers库都能提供便捷的支持。

### 1.1.5 扩展阅读

对于想要深入学习Python、TensorFlow、PyTorch以及Hugging Face的读者，以下资源可以极大地帮助你扩展知识和技能。这些建议的阅读材料和网站会为你提供从基础到高级的内容，确保你能够全面理解这些工具和库。
1. **Python**

    - 《Python核心编程》详细介绍了Python的核心概念，适合初学者和中级程序员。
    - 《流畅的Python》深入浅出地讲解了Python高级用法，强烈推荐给有一定Python经验的开发者。 
    - 官方Python文档的内容深入浅出，是学习Python不可多得的免费资源。
2. **TensorFlow**
   
    - 《TensorFlow：实战Google深度学习框架》覆盖TensorFlow的基础与进阶应用，非常适合系统学习。 
    - TensorFlow官方文档详尽地介绍了TensorFlow的所有特性。 
    - 由吴恩达和他的团队设计的TensorFlow实践课程，其中集合了TensorFlow在实践中的应用。
4. **PyTorch**
   
    - 《PyTorch深度学习实战》通过实例教授PyTorch的基础和高级知识点，适合各层次读者。 
    - PyTorch官方文档提供了大量示例代码和实践指南，适合新手迅速上手。 
    - “60分钟上手使用PyTorch进行深度学习”项目可以帮助新手快速入门，其内容涵盖PyTorch的基本概念。
6. **Hugging Face**
   
    - “Transformer模型实战”探索了Hugging Face生态系统，并以项目为导向介绍Transformer模型。 
    - Hugging Face官方文档包含使用transformers库的详细指南和API文档。 
    - Hugging Face的transformers库课程是免费的在线课程，内容覆盖从基础到高级的transformers库知识。

以上资源除了介绍基础内容以外，还深入阐释了一些复杂的主题，可以帮助读者打下坚实的技术基础。

### 1.2 常见模型介绍
在1.1节中，我们学习了一些常用的技术框架或工具，本节将对常见模型进行介绍。

在机器学习领域，模型大致可以分为两大类——判别式（discriminative）模型和生成式（generative）模型。这两类模型在目标、方法和应用方面都有所不同。

#### 1.2.1 判别式模型

判别式模型的主要任务是学习输入数据和输出标签之间的映射关系。简而言之，它们试图直接从输入数据预测输出标签。判别式模型关注于边界，即不同类别或结果之间的分界线。常见的判别式模型包括逻辑斯谛回归（Logistic Regression, LR）、支持向量机（Support Vector Machine, SVM）、深度神经网络（Deep Neural Network, DNN）等。

1. **逻辑斯谛回归**

逻辑斯谛回归是一种广泛使用的线性分类器，主要用于二分类问题。它通过sigmoid函数将线性回归的输出压缩到[0,1]区间，以表示某个类别的概率。

2. **支持向量机**

支持向量机是一种强大的分类器，通过寻找最大间隔超平面以最好地分割不同的类别。支持向量机在处理中小型复杂数据集方面表现突出，尤其是在高维空间。使用支持向量机对白点、黑点进行分类，可通过寻找合适的超平面实现。 


![image](https://github.com/user-attachments/assets/0b4f22b8-4f51-43b3-89c1-097ae3ebc9d1)


3. **深度神经网络**

深度神经网络通过组合多个非线性处理层来学习复杂的数据表示。深度神经网络在语音识别、图像识别、NLP等领域取得了巨大成功。



#### 1.2.2 生成式模型

与判别式模型不同，生成式模型试图了解数据是如何生成的。它们通过学习输入数据的分布来生成新的数据实例。生成式模型不仅能够执行分类任务，还能够生成类似于训练集的全新数据样本。常见的生成式模型包括高斯混合模型（Gaussian Mixture Model, GMM）、隐马尔可夫模型（Hidden Markov Model, HMM）和近年来非常流行的生成对抗网络（Generative Adversarial Network, GAN）及扩散模型（Diffusion Model, DM）等。

1. **高斯混合模型**

高斯混合模型是一种概率模型，假设所有的数据点都是由有限数量的高斯分布混合生成的。高斯混合模型常用于聚类分析和密度估计。

2. **隐马尔可夫模型**

隐马尔可夫模型是一种统计模型，假定系统可以用一个隐藏的马尔可夫链生成观测数据。隐马尔可夫模型广泛应用于时间序列数据的分析，如语音识别和NLP。 

![image](https://github.com/user-attachments/assets/d0920e78-3a0e-4a53-a5a9-892cb335c210)


3. **生成对抗网络**

生成对抗网络由两部分组成——生成器和判别器。生成器负责产生看起来像真实数据的假数据，而判别器的任务是区分生成的数据和真实数据。生成对抗网络在图像生成、风格转换、图像超分辨率等方面显示出惊人的效果。

4. **扩散模型**

扩散模型是一种近年来快速崛起的生成式模型，它通过模拟反向扩散过程来生成数据。这个过程首先从一个随机噪声分布开始，然后逐步通过学习的扩散过程去除噪声，最终生成与真实数据相似的样本。扩散模型在图像和音频合成领域取得了显著成果，尤其是在生成高质量、细节丰富的图像方面表现出色。

生成式模型和判别式模型各有优势及适用场景。判别式模型凭借直接学习输入与输出之间关系的能力，在许多预测和分类任务中表现卓越。而生成式模型则因为能够揭示数据背后的分布特征和生成新数据的能力，在数据增强、未来预测等任务中展现出巨大的潜力。随着研究的深入和技术的发展，两类模型都在不断进化，以解决越来越多的实际问题。

### 1.3 数据和任务

随着人工智能技术的飞速发展，生成式AI已经成为科技领域最令人兴奋的前沿技术之一。它利用深度学习模型，通过理解大量的数据来创造全新的内容，这些内容涵盖文本、图像、音频甚至视频等多种形式。它不仅为人类创造力的延伸提供了无限可能，而且在很多行业开辟了新的应用场景。本节将深入探讨生成式AI在不同数据类型和常见任务中的应用，包括如何运用先进模型进行文本生成、图像创作、音频生产以及视频制作。


#### 1.3.1 数据类型

常见的数据类型如下。

- **文本数据**：文本数据是生成式AI中最常见的数据类型之一，广泛应用于聊天机器人、自动写作、内容生成等任务。这些文本数据可以来自书籍、文章、网页等多种来源。

- **图像数据**：图像数据涉及静态的视觉内容，包括照片、绘画、设计图等。生成式AI在这一领域的应用包括生成新的艺术作品、编辑现有图像以及创建虚拟场景等。 

- **音频数据**：音频数据包括声音记录和音乐。生成式AI能够创造新的音乐作品、模仿特定的声音或音乐风格，以及进行语音合成和变换等。


#### 1.3.2 常见任务

1. **文本生成**

文本生成任务主要包括如下内容。
    - **新闻文章**：自动化生成新闻内容，旨在提高新闻报道的效率和速度。 
    - **故事创作**：创造新颖的故事和小说，为作家和内容创造者提供灵感。 
    - **代码生成**：自动生成代码片段，帮助开发者提高开发效率。

文本总结是文本生成最广泛的应用之一，即将长文档缩写成较短的文本，同时保留其中的重要信息。一些模型可以从初始输入中提取文本，而其他模型可以生成全新的文本。
示例代码：
```Python
from transformers import pipeline

classifier = pipeline("summarization")
classifier("Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of Île-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.")
# [{'summary_text': " Paris is the capital and most populous city of France... "}]
```
可以看到，借助Hugging Face的transformers库，可以快速完成文本生成任务。

2. **图像生成**
图像生成任务主要包括如下内容。
    - **艺术创作**：利用AI创作独特的艺术品，模仿或超越传统的艺术风格。 
    - **图像编辑**：自动调整图像参数或进行复杂的编辑任务，如风格转换、面部编辑等。 
    - **虚拟现实内容**：生成虚拟现实环境中的视觉内容，用于游戏、模拟和教育等场景。

图1-3展示了无条件图像生成，即在任何上下文（如提示文本或另一幅图像）中无条件生成图像的任务。一旦训练完成，模型将创造出类似其训练数据分布的图像。这个领域中非常流行的模型包括生成对抗网络和变分自编码器模型。由于此类模型不如Stable Diffusion模型更有  （此处文字显示不全） 
