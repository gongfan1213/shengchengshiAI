用，因此本书不会花大量篇幅介绍这类较为过时的模型。

图1-3展示了无条件图像生成，即输入提示想要生成的图像数量，通过无条件图像生成模型，输出相应图像。 


![image](https://github.com/user-attachments/assets/4221c356-728f-49f7-9213-36ebdac7ae52)


图1-4展示了文生图模型的应用过程，即输入文本生成图像。这些模型可以用来根据文本提示生成或修改图像。


![image](https://github.com/user-attachments/assets/d7044d44-1ed6-421e-8349-260a0e64f92a)


示例代码：
```Python
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler

model_id = "stabilityai/stable-diffusion-2"
scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder="scheduler")
pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]
```

#### 3. 音频生成

音频生成任务主要包括如下内容。
- **音乐创作**：创造新的音乐作品，模仿特定艺术家或风格，或完全创新。
- **语音合成**：生成清晰、自然的语音输出，用于虚拟助手、有声读物和其他应用。

音频到音频是一类任务，其中输入是一个音频，输出是一个或多个生成的音频。示例任务如语音增强和声源分离等。图1-5展示了音频到音频转换的过程。

![image](https://github.com/user-attachments/assets/95916002-0437-4d6c-808e-b9962ac901b5)


音频到音频转换的示例代码如下。
```Python
from speechbrain.pretrained import SpectralMaskEnhancement
model = SpectralMaskEnhancement.from_hparams(
    "speechbrain/mtl-mimic-voicebank"
)
model.enhance_file("file.wav")
```

如图1-6所示，文本转语音（Text - to - Speech, TTS）模型可用于任何需要将文本转换成模仿人声的语音应用中。在智能设备上，TTS模型被用来创建语音助手。与通过录制声音并映射它们来构建助手的拼接方法相比，TTS模型是更好的选择，因为TTS模型生成的输出包含自然语音中的元素，如重音。在机场和公共交通的公告系统中，TTS模型被广泛使用，主要用于将给定文本的公告转换成语音。

![image](https://github.com/user-attachments/assets/14da4a73-dd73-4ffe-ad2b-1b19514be5df)


文本转语音的示例代码如下。
```Python
from transformers import pipeline
synthesizer = pipeline("text-to-speech", "suno/bark")
synthesizer("Look I am generating speech in three lines of code!")
```

#### 4. 视频生成
视频生成任务主要包括如下内容。
- **基于脚本的视频生成**：根据提供的文本脚本创建短视频内容，如营销视频，解释产品工作原理等。
- **内容格式转换**：将长篇文本、博文、文章和文本文件转换成视频，用于制作教育视频，让内容变得更加吸引人，互动性更强。 
- **配音和语音**：创建AI新闻播报员以传递日常新闻，或者由电影制作人创建短片或音乐视频等。

视频生成任务的变体如下。
- **文本到视频编辑**：生成基于文本的视频样式和局部属性编辑，简化裁剪、稳定、色彩校正、调整大小和音频编辑等任务。 
- **文本到视频搜索**：检索与给定文本查询相关的视频，通过语义分析、视觉分析和时间分析，确定与文本查询最相关的视频。 
- **文本驱动的视频预测**：根据文本描述生成视频序列，目标是生成视觉上真实且与文本描述语义一致的视频。 
- **视频翻译**：将视频从一种语言翻译成另一种语言，或允许使用非英语句子查询多语言文本 - 视频模型，适用于希望观看包含自己不懂的语言的视频的人群，特别是当有多语言字幕可供训练时。

视频生成（这里使用了文生视频模型，即从文字生成视频模型）的示例如图1-7所示。

![image](https://github.com/user-attachments/assets/f2a47290-d998-499c-a719-7bc189c00187)


#### 5. 多模态任务
如图1-8所示，图像问答（也称为视觉问答）是基于图像回答开放式问题的任务。它们对自然语言问题输出自然语言响应。

![image](https://github.com/user-attachments/assets/d77d85b3-b630-4139-941e-b88d4ca44f39)


图像问答的示例代码如下。
```Python
from PIL import Image
from transformers import pipeline

vqa_pipeline = pipeline("visual-question-answering")
image = Image.open("elephant.jpeg")
question = "Is there an elephant?"

vqa_pipeline(image, question, top_k=1)
# [{'score': 0.999815044151306, 'answer': 'yes'}]
```

如图1-9所示，文档问答（也称为文档视觉问答）是指在文档图像上回答问题的任务。文档问答模型将文档 - 问题对作为输入，并返回自然语言的答案。这类模型通常依赖于多模态特征，涉及文本、单词位置（边界框）和图像等。

![image](https://github.com/user-attachments/assets/f7df70f0-6cd0-4c95-976b-1ea52aaa27f6)


文档问答的示例代码如下。
```Python
from transformers import pipeline
from PIL import Image

pipe = pipeline("document-question-answering", model="naver-clova-ix/donut-base-finetuned-docvqa")
question = "What is the purchase amount?"
image = Image.open("your-document.png")

pipe(image=image, question=question)
# [{'answer': '20,000$'}]
```

### 1.4 小结
本章提供了一次全面的技术之旅，从基础的编程语言和框架介绍，到深入探讨判别式模型与生成式模型的异同，再到概览生成式AI能够处理的数据类型和任务。通过这一系列精心安排的内容，我们希望读者能够获得一个清晰的生成式AI领域全貌，深刻理解其核心技术与应用，并为进一步的学习和研究奠定坚实的基础。

在这个技术日新月异的时代，生成式AI已经崛起为一个热门话题，其背后的技术正在不断地演进。从最初的简单模型到如今高度复杂的系统，生成式AI正展现出无限的可能性。我们满怀期待，随着技术的日益成熟和应用场景的持续拓展，生成式AI将在未来带来更多的惊喜和突破。对于读者而言，理解并掌握本章所介绍的内容，是迈入这一激动人心领域的关键的第一步。 
