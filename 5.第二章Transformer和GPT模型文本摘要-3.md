### 2.5 案例二：文本总结
在这个指南中，我们将一起探索文本摘要的技巧和秘密。想象一下，你有一大堆文档或文章，需要快速了解其要点，这时就可以使用文本摘要。文本摘要技术是NLP领域的一个重要分支，它涵盖了从长文本中提取关键信息的各种方法。这些方法大致分为两类：提取式摘要和生成式摘要。提取式摘要侧重于从原文中挑选出关键句子，而生成式摘要则重构信息，产生全新的文本内容。

#### 2.5.1 安装
我们建议你使用jupyternotebook来运行下面的代码（或者Google Colab）。你可能需要安装Hugging Face的transformers库和Datasets库以及其他依赖项。当然，也可以在Python环境中运行如下代码。
```Python
!pip install datasets evaluate transformers rouge-score nltk
```

为了能够与社区分享你的模型，并通过推理API生成图2 - 5所示的结果，你还需要遵循一些其他步骤。

![image](https://github.com/user-attachments/assets/1108c0cd-61a1-42d9-b9be-2a2785140277)


首先，从Hugging Face网站（如果还没有注册，请先注册）获取身份验证Token，然后执行以下代码并输入用户名和密码。
```Python
from huggingface_hub import notebook_login
notebook_login()
```

接下来，安装Git - LFS，之后在终端中运行以下命令。
```Shell
apt install git-lfs
```

确保transformers库版本至少为4.11.0。示例代码如下。
```Python
import transformers
print(transformers.__version__)
# 4.11.0
```

接下来我们将看到如何对Hugging Face的transformers库进行微调，以进行总结任务。我们将使用XSsum数据集（其中包含BBC文章和单句总结）在总结任务上进行模型训练。使用Hugging Face的Datasets库，我们能够非常简单地加载此任务的数据集；使用Hugging Face的框架下，我们还会使用Trainer API对模型进行微调。

本教程的代码可以加载Hugging Face的Model Hub中任何模型的checkpoint（检查点），只要该模型在transformers库中有对应的版本即可。这里将t5 - small checkpoint作为样例。
```Python
model_checkpoint = "t5-small"
```

#### 2.5.2 加载数据集
我们将使用Hugging Face的Datasets库下载数据并获取评估所需的度量标准（与基准模型进行比较）。这可以通过load_dataset或load_metric函数轻松完成这项任务。示例代码如下。
```Python
from datasets import load_dataset
from evaluate import load
raw_datasets = load_dataset('xsum')
metric = load('rouge')
```

运行上述代码，弹出如下警告信息。
```
/home/tiger/.local/lib/python3.9/site-packages/datasets/load.py:1429:
FutureWarning: The repository for xsum contains custom code which must be
executed to correctly load the dataset.
Passing `trust_remote_code=True` will be mandatory to load this dataset from
the next major release of `datasets`.
warnings.warn(...)
The dataset object itself is DatasetDict, which contains one key for the
training, validation and test set:
```

我们可以通过如下代码检查数据集里面的元素。
```Python
raw_datasets
```

运行上述代码，输出如下。
```
DatasetDict({
    train: Dataset({
        features: ['document','summary', 'id'],
        num_rows: 204045
    })
    validation: Dataset({
        features: ['document','summary', 'id'],
        num_rows: 11332
    })
    test: Dataset({
        features: ['document','summary', 'id'],
        num_rows: 11334
    })
})
```

可以发现数据集对象本身是DatasetDict，包含训练、验证和测试集3个键（key）。

为了访问实际元素，需要先选择raw_datasets的一个键，然后给出一个索引，例如1。示例代码如下。
```Python
raw_datasets["train"][1]
```

运行上述代码，输出如下。
```
{
    'document': 'A fire alarm went off at the Holiday Inn in Hope Street at about 04:20 BST on Saturday and guests were asked to leave the hotel.\nAs they gathered outside they saw the two buses, parked side - by - side in the car park, engulfed in flames.\nThe driver of one of the buses said many of the passengers had left personal belongings on board and these had been destroyed.\nBoth groups have organised replacement coaches and will begin their tour of the north coast later than they had planned.\nPolice have appealed for information about the attack.\nInsp David Gibson said: "It appears as though the fire started under one of the buses before spreading to the second."\n"While the exact cause is still under investigation, it is thought that the fire was started deliberately."',
   'summary': 'Two tourist buses have been destroyed by fire in a suspected arson attack in Belfast city centre.',
    'id': '40143035'
}
```

为了展示一些数据，我们可以使用如下函数随机显示数据集中的一些示例。
```Python
import datasets
import random
import pandas as pd
from IPython.display import display, HTML

def show_random_elements(dataset, num_examples=5):
    assert num_examples <= len(dataset), "Can't pick more elements than there are in the dataset."
    picks = []
    for _ in range(num_examples):
        pick = random.randint(0, len(dataset) - 1)
        while pick in picks:
            pick = random.randint(0, len(dataset) - 1)
        picks.append(pick)
    
    df = pd.DataFrame(dataset[picks])
    for column, typ in dataset.features.items():
        if isinstance(typ, datasets.ClassLabel):
            df[column] = df[column].transform(lambda i: typ.names[i])
    display(HTML(df.to_html()))
```

训练之前我们还需要选择一个评测器，示例代码如下。
```Python
metric
```

运行上述代码，输出如下。
```
EvaluationModule(name: "rouge", module_type: "metric", features:
[{'predictions': Value(dtype='string', id='sequence'),'references': Sequence
(feature=Value(dtype='string', id='sequence'), length=-1, id=None)},
{'predictions': Value(dtype='string', id='sequence'),'references':
Value(dtype='string', id='sequence')}], usage: """
Calculates average rouge scores for a list of hypotheses and references
Args:
    predictions: list of predictions to score. Each prediction
        should be a string with tokens separated by spaces.
    references: list of reference for each prediction. Each
        reference should be a string with tokens separated by spaces.
    rouge_types: A list of rouge types to calculate.
        Valid names:
            "rouge{n}" (e.g. "rouge1", "rouge2") where: (n) is the n-gram
based scoring,
            "rougeL": Longest common subsequence based scoring.
            "rougeLsum": rougeLsum splits text using "
".
    See details in https://github.com/huggingface/datasets/issues/617
    use_stemmer: Bool indicating whether Porter stemmer should be used to strip
word suffixes.
    use_aggregator: Return aggregates if this is set to True
Returns:
    rouge1: rouge_1 (f1),
    rouge2: rouge_2 (f1),
    rougeL: rouge_1 (f1),
    rougeLsum: rouge_lsum (f1)
Examples:
    >>> rouge = evaluate.load('rouge')
    >>> predictions = ["hello there", "general kenobi"]
    >>> references = ["hello there", "general kenobi"]
    >>> results = rouge.compute(predictions=predictions, references=references)
    >>> print(results)
    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}
""", stored_examples: 0)
```

可以看到，此次使用的评测器是一种datasets.Metric。

我们可以调用metric对象的compute方法对模型的预测和数据集中的标签进行计算，以获得指标，示例代码如下。
```Python
fake_preds = ["hello there", "general kenobi"]
fake_labels = ["hello there", "general kenobi"]
metric.compute(predictions=fake_preds, references=fake_labels)
```

运行上述代码，输出如下。
```
{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}
``` 
