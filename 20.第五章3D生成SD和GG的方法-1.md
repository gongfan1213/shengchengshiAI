
# 5.4 3D 生成：Stable Diffusion 和 Generative Gaussian Splatting 方法
Stable Diffusion的核心思想是通过渐进地将噪声注入输入图像中，逐步生成具有逼真细节的图像。相比于传统的生成对抗网络方法，Stable Diffusion不需要在训练期间对抗性地优化生成器和判别器，从而更加稳定和易于训练。它已经在图像生成、修复、编辑等任务中取得了显著的成果，并被认为是一种非常有前景的生成模型方法。

DreamGaussian是一种新型的3D内容生成框架，它采用了一种称为3D高斯点阵的模型。这一创新能够更快速地生成高质量的带纹理网格，并且只须短短的2分钟就能从单个视角图像生成完整的三维模型，比传统方法更高效。
#### 5.4.1 配置流程
本节项目的硬件条件如下。
- Ubuntu 22操作系统、PyTorch 1.12、CUDA 11.6、V100 GPU。
- Windows 10操作系统、PyTorch 2.1、CUDA 12.1、3070 GPU。

在将项目下载到本地后，可以进入项目目录，为该项目配置运行环境。示例代码如下。
### Shell
```bash
cd dreamgaussian
pip install -r requirements.txt
# a modified gaussian splatting (+ depth, alpha rasterization)
git clone --recursive https://github.com/ashawkey/diff-gaussian-rasterization
pip install./diff-gaussian-rasterization
# simple-knn
pip install./simple-knn
# nvdiffrast
pip install git+https://github.com/NVlabs/nvdiffrast/
# kiukit
pip install git+https://github.com/ashawkey/kiukit
# To use MVDream, also install:
pip install git+https://github.com/bytedance/MVDream
# To use ImageDream, also install:
pip install git+https://github.com/bytedance/ImageDream/#subdirectory=extern/ImageDream
```
在安装官方环境配置后，尝试运行时可能会出现找不到某个配置文件的问题，具体的报错信息如下。
### Shell
```bash
glutil.h fatal error: EGL/egl.h: No such file or directory
```
这是因为计算机中没有安装一些依赖项，只须执行下面命令就可以解决该问题。
### Shell
```bash
sudo apt-get install libegl1-mesa-dev
```
#### 5.4.2 运行示例
在配置项目环境后，就可以尝试运行这个项目了。该项目可以实现多种功能，包括Image-to-3D、Text-to-3D等。为了便于演示，这里以Text-to-3D为例进行示范。示例代码如下。
### Shell
```bash
### training gaussian stage
python main.py --config configs/text.yaml prompt="a photo of an icecream" save_path=icecream
### training mesh stage
python main2.py --config configs/text.yaml prompt="a photo of an icecream" save_path=icecream
```
可以看到，运行的示例代码中共有两条命令，分别是training gaussian stage和training mesh stage。这是因为本项目在生成最终的3D模型时，为了提高图形的质量效果，将生成模型的部分分为生成基于点云的大致形状和生成带网格的3D模型两个步骤。如图5-18所示，第1个阶段主要负责根据提示，生成3D模型的大致轮廓；第2个阶段负责在第1个阶段生成模型的基础上，进一步精细化模型的外形和纹理，让模型看上去更加细致，纹理更加清晰。 （此处未详细描述图5-18内容 ）




![image](https://github.com/user-attachments/assets/99efcdca-24a8-4963-8e3e-7e363e06249c)




接下来依次运行上述的两条命令，但是可能会出现如下报错信息。
### Python
```python
eglInitialize() failed Aborted (core dumped)
```
这是因为在text.yaml文件中，有一个隐含的参数叫作force_cuda_rast=False，这个参数会让程序不在GPU上运行。因为我们提前配置好了cuda环境，所以为了让程序在GPU上运行，应该将参数设置为force_cuda_rast=True。再次运行后就不会报错了。

在运行后，logs文件夹下会出现对应的模型文件。将第1条命令运行生成的icecream_mesh.obj、icecream_mesh.mtl和icecream_mesh_albedo.png文件一起放入可以查看3D文件的查看器中，就可以看到图5-19所示的模型。

同理，将第2条命令运行生成的icecream.obj、icecream.mtl和icecream_albedo.png文件放入3D查看器中，就可以看到图5-20所示的模型。 （此处未详细描述图5-19、图5-20内容 ） 

对比图5-19和图5-20中的图像，可以很明显地发现，经过mesh阶段精细化处理的icecream模型，相比于只经过第1个阶段生成的模型，在细节和真实程度上有很明显的提升。

![image](https://github.com/user-attachments/assets/b6831a7b-a9c5-4b72-a2f6-18bf72f12346)


#### 5.4.3 关键原理解释
### 1. 模型快速生成
生成式高斯喷溅是DreamGaussian方法的核心，其设计用于高效地初始化3D几何形状和外观。这一过程是通过将3D Gaussian Splatting适用于生成任务实现的。3D高斯模型通过一组3D高斯来表示3D信息，每个高斯由中心位置、缩放因子、旋转四元数、不透明度值和颜色特征组成。通过将这些3D高斯投影到图像平面上，进行体积渲染来评估最终颜色和透明度，实现对场景的渲染。

网格提取算法旨在将生成的3D高斯转换为多边形网格，并进一步细化纹理。这一任务在之前未被探索过，DreamGaussian提出了一种高效的算法从3D高斯中提取具有纹理的多边形网格。

首先，将3D空间划分为多个块，并对每个块内的3D高斯进行局部密度查询，以生成一个密集的3D密度网格。通过应用Marching Cubes算法从密度网格中提取网格表面，随后进行简化和重网格化处理，以生成平滑的多边形网格。

利用已获取的网格几何信息，将渲染的RGB图像反投影到网格表面并作为纹理。这一过程通过选择多个视角渲染对应的RGB图像，并基于UV坐标将像素值反投影到纹理图像上完成。

这两个步骤结合起来，不仅实现了从3D高斯到多边形网格的转换，而且保证了生成的3D模型具有详细且逼真的纹理。生成式高斯喷溅和网格提取算法共同构成了DreamGaussian方法的核心，为3D内容的快速高效生成提供了强有力的技术支持。
### 2. 模型细化
在通过3D高斯分布生成3D模型的过程中，直接生成的结果往往在纹理上看起来比较模糊，缺乏细节。这主要是因为在SDS（Score Distillation Sampling）优化过程中存在的歧义性，导致模型在未重建区域的密度化（densification）或已重建区域的修剪（pruning）上难以做出准确的调整。为了解决这个问题，UV空间纹理细化阶段被设计出来，用于显式地细化模型的纹理，从而提高生成3D内容的质量。

该阶段采用一个多步骤的去噪过程来细化纹理图像。这一过程基于2D扩散模型，通过在粗糙纹理图像中加入随机噪声，然后逐步去除噪声来增强细节。细化后的纹理图像会有更好的细节表现，同时保持原有内容的完整性。

之后通过最小化细化后的纹理图像与初始粗糙的纹理图像之间的均方误差，对纹理图像进行优化。这一步骤确保了纹理细化过程中内容的一致性和细节的增强。 














